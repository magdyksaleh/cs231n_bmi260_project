{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import sampler\n",
    "import skorch\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as T\n",
    "import torchvision.models as models\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "# matplotlib.use('agg')\n",
    "import matplotlib.pyplot as plt\n",
    "from Lung_dataset import ILDDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using device: cuda\n"
     ]
    }
   ],
   "source": [
    "USE_GPU = True\n",
    "\n",
    "dtype = torch.float32 # we will be using float throughout this tutorial\n",
    "\n",
    "if USE_GPU and torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "# Constant to control how frequently we print train loss\n",
    "print_every = 100\n",
    "\n",
    "print('using device:', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_TOTAL = 1982\n",
    "NUM_TRAIN = 1500\n",
    "#add path as absolute path for root dir\n",
    "\n",
    "im_size = 128\n",
    "\n",
    "lung_dataset_train = ILDDataset(csv_file=r'C:/Users/Akrofi/Desktop/CS 231/Project/train_labels.csv', \n",
    "                          root_dir=r'C:/Users/Akrofi/Desktop/CS 231/Project/train',mask=True, train=True, resize=im_size)#, transform=transform)\n",
    "\n",
    "\n",
    "#add path as absolute path for root dir\n",
    "lung_dataset_test = ILDDataset(csv_file=r'C:/Users/Akrofi/Desktop/CS 231/Project/test_labels.csv', \n",
    "                          root_dir=r'C:/Users/Akrofi/Desktop/CS 231/Project/test', mask=True, train=False, resize=im_size)#, transform=transform)\n",
    "\n",
    "\n",
    "loader_train = DataLoader(lung_dataset_train, batch_size=32, \n",
    "                          sampler=sampler.SubsetRandomSampler(range(NUM_TRAIN)))\n",
    "\n",
    "loader_val = DataLoader(lung_dataset_train, batch_size=32, \n",
    "                          sampler=sampler.SubsetRandomSampler(range(NUM_TRAIN, NUM_TOTAL)))\n",
    "\n",
    "loader_test = DataLoader(lung_dataset_test, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP4AAAD8CAYAAABXXhlaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2833f4f2f98>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label: 1\n"
     ]
    }
   ],
   "source": [
    "#show datasample\n",
    "sample = lung_dataset_train[120]\n",
    "print(sample.shape)\n",
    "plt.imshow(sample[0], cmap='gray')\n",
    "plt.show()\n",
    "print(\"label: \" + str(sample[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def flatten(x):\n",
    "    N = x.shape[0] # read in N, C, H, W\n",
    "    return x.view(N, -1)  # \"flatten\" the C * H * W values into a single vector per image\n",
    "\n",
    "class Flatten(nn.Module):\n",
    "    def forward(self, x):\n",
    "        return flatten(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_model(freeze=False):\n",
    "    \"\"\"\n",
    "    Used to fetch model for classification\n",
    "    \"\"\"\n",
    "#     channel_1 = 64\n",
    "#     channel_2 = 64\n",
    "#     channel_3 = 128\n",
    "\n",
    "#     in_channel = 62\n",
    "    num_classes = 3\n",
    "\n",
    "    model = models.resnet50(pretrained=True)\n",
    "    model.avgpool = nn.AvgPool2d(1, stride=1)\n",
    "    model.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=1, bias=False)\n",
    "    if(freeze==True):\n",
    "        for param in model.parameters():\n",
    "            param.requires_grad = False\n",
    "    model.fc = nn.Linear(8192, num_classes)\n",
    "    model.dropout = nn.Dropout2d(p=0.7)\n",
    "\n",
    "    \n",
    "    return model\n",
    "    # from skorch import NeuralNetClassifier\n",
    "\n",
    "    # net = NeuralNetClassifier(\n",
    "    #     module=model,\n",
    "    #     criterion = nn.CrossEntropyLoss,\n",
    "    #     optimizer=optim.Adam,\n",
    "    #     train_split=None,\n",
    "    #     max_epochs=5,\n",
    "    #     lr = learning_rate,\n",
    "    #     warm_start = True,\n",
    "    #     device = device\n",
    "    # )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def check_accuracy(loader, model, train=False):\n",
    "    if loader.dataset.train and train == True:\n",
    "        print('Checking accuracy on training set')\n",
    "    elif loader.dataset.train:\n",
    "        print('Checking accuracy on validation set')\n",
    "    else:\n",
    "        print('Checking accuracy on test set')   \n",
    "    num_correct = 0\n",
    "    num_samples = 0\n",
    "    model.eval()  # set model to evaluation mode\n",
    "    with torch.no_grad():\n",
    "        for x, y in loader:\n",
    "            x = x.to(device=device, dtype=dtype)  # move to device, e.g. GPU\n",
    "            x.unsqueeze_(1)\n",
    "            y = y.to(device=device, dtype=torch.long)\n",
    "            scores = model(x)\n",
    "            _, preds = scores.max(1)\n",
    "            num_correct += (preds == y).sum()\n",
    "            num_samples += preds.size(0)\n",
    "        acc = float(num_correct) / num_samples\n",
    "        print('Got %d / %d correct (%.2f)' % (num_correct, num_samples, 100 * acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimizer, epochs=1, overfit=False):\n",
    "    \"\"\"\n",
    "    Inputs:\n",
    "    - model: A PyTorch Module giving the model to train.\n",
    "    - optimizer: An Optimizer object we will use to train the model\n",
    "    - epochs: (Optional) A Python integer giving the number of epochs to train for\n",
    "    \n",
    "    Returns: Nothing, but prints model accuracies during training.\n",
    "    \"\"\"\n",
    "    model = model.to(device=device)  # move the model parameters to CPU/GPU\n",
    "    for e in range(epochs):\n",
    "        for t, (x, y) in enumerate(loader_train):\n",
    "            model.train()  # put model to training mode\n",
    "            x = x.to(device=device, dtype=dtype)  # move to device, e.g. GPU\n",
    "            y = y.to(device=device, dtype=torch.long)\n",
    "            \n",
    "            x.unsqueeze_(1)\n",
    "            scores = model(x)\n",
    "            loss = F.cross_entropy(scores, y)\n",
    "            \n",
    "            reg = torch.tensor(1e-4, device= device, dtype=dtype)\n",
    "            l2_reg = torch.tensor(0. , device= device, dtype=dtype)\n",
    "            for param in model.parameters():\n",
    "                l2_reg += torch.norm(param)\n",
    "            loss += reg * l2_reg\n",
    "\n",
    "            # Zero out all of the gradients for the variables which the optimizer\n",
    "            # will update.\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # This is the backwards pass: compute the gradient of the loss with\n",
    "            # respect to each  parameter of the model.\n",
    "            loss.backward()\n",
    "\n",
    "            # Actually update the parameters of the model using the gradients\n",
    "            # computed by the backwards pass.\n",
    "            optimizer.step()\n",
    "            \n",
    "            if t % print_every == 0:\n",
    "                print('Iteration %d, loss = %.4f' % (t, loss.item()))\n",
    "                if(overfit):\n",
    "                    check_accuracy(loader_train, model, train=True)\n",
    "                check_accuracy(loader_val, model)\n",
    "                print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0, loss = 1.2535\n",
      "Checking accuracy on training set\n",
      "Got 693 / 1500 correct (46.20)\n",
      "Checking accuracy on validation set\n",
      "Got 87 / 482 correct (18.05)\n",
      "\n",
      "Iteration 0, loss = 0.8052\n",
      "Checking accuracy on training set\n",
      "Got 1206 / 1500 correct (80.40)\n",
      "Checking accuracy on validation set\n",
      "Got 137 / 482 correct (28.42)\n",
      "\n",
      "Iteration 0, loss = 0.3123\n",
      "Checking accuracy on training set\n",
      "Got 1330 / 1500 correct (88.67)\n",
      "Checking accuracy on validation set\n",
      "Got 148 / 482 correct (30.71)\n",
      "\n",
      "Iteration 0, loss = 0.2757\n",
      "Checking accuracy on training set\n"
     ]
    }
   ],
   "source": [
    "model1 = get_model()\n",
    "optimizer = optim.Adam(model1.parameters(), lr = 0.0001)\n",
    "train(model1, optimizer, epochs=5, overfit=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-388996727f97>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mbest_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "# best_model = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0, loss = 1.1195\n",
      "Checking accuracy on training set\n",
      "Got 520 / 1500 correct (34.67)\n",
      "Checking accuracy on validation set\n",
      "Got 248 / 482 correct (51.45)\n",
      "\n",
      "Iteration 0, loss = 0.7336\n",
      "Checking accuracy on training set\n",
      "Got 1120 / 1500 correct (74.67)\n",
      "Checking accuracy on validation set\n",
      "Got 240 / 482 correct (49.79)\n",
      "\n",
      "Iteration 0, loss = 0.3912\n",
      "Checking accuracy on training set\n",
      "Got 1272 / 1500 correct (84.80)\n",
      "Checking accuracy on validation set\n",
      "Got 250 / 482 correct (51.87)\n",
      "\n",
      "Iteration 0, loss = 0.6592\n",
      "Checking accuracy on training set\n",
      "Got 1321 / 1500 correct (88.07)\n",
      "Checking accuracy on validation set\n",
      "Got 294 / 482 correct (61.00)\n",
      "\n",
      "Iteration 0, loss = 0.1504\n",
      "Checking accuracy on training set\n",
      "Got 1398 / 1500 correct (93.20)\n",
      "Checking accuracy on validation set\n",
      "Got 265 / 482 correct (54.98)\n",
      "\n",
      "Iteration 0, loss = 0.2289\n",
      "Checking accuracy on training set\n",
      "Got 1390 / 1500 correct (92.67)\n",
      "Checking accuracy on validation set\n",
      "Got 263 / 482 correct (54.56)\n",
      "\n",
      "Iteration 0, loss = 0.2539\n",
      "Checking accuracy on training set\n",
      "Got 1420 / 1500 correct (94.67)\n",
      "Checking accuracy on validation set\n",
      "Got 284 / 482 correct (58.92)\n",
      "\n",
      "Iteration 0, loss = 0.0592\n",
      "Checking accuracy on training set\n",
      "Got 1427 / 1500 correct (95.13)\n",
      "Checking accuracy on validation set\n",
      "Got 291 / 482 correct (60.37)\n",
      "\n",
      "Iteration 0, loss = 0.2558\n",
      "Checking accuracy on training set\n",
      "Got 1413 / 1500 correct (94.20)\n",
      "Checking accuracy on validation set\n",
      "Got 268 / 482 correct (55.60)\n",
      "\n",
      "Iteration 0, loss = 0.1074\n",
      "Checking accuracy on training set\n",
      "Got 1440 / 1500 correct (96.00)\n",
      "Checking accuracy on validation set\n",
      "Got 273 / 482 correct (56.64)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# model = get_model()\n",
    "# # optimizer = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr = 0.001)\n",
    "# optimizer = optim.Adam(model.parameters(), lr = 0.0001)\n",
    "# train(model, optimizer, epochs=10, overfit=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking accuracy on validation set\n",
      "Got 197 / 482 correct (40.87)\n"
     ]
    }
   ],
   "source": [
    "#Check validation set\n",
    "# check_accuracy(loader_val, model1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import KFold\n",
    "# from sklearn import metrics\n",
    "\n",
    "# # for epoch in range(5):\n",
    "# kf = KFold(n_splits=3, shuffle = True)\n",
    "# accuracies=[]\n",
    "# for train_index, test_index in kf.split(x):\n",
    "#     accuracies=[]\n",
    "# #     (N, C1, C2, S) = x.shape \n",
    "# #     x = x.reshape((N, 62, 512, 512))\n",
    "# #     y = y.reshape((y.shape[0]))\n",
    "# #     print(x.shape)\n",
    "# #     print(y.shape)\n",
    "# #     print(train_index)\n",
    "# #     print(test_index)\n",
    "#     xk_train, xk_test = x[train_index], x[test_index]\n",
    "#     yk_train, yk_test = y[train_index], y[test_index]\n",
    "#     net.fit(xk_train,yk_train)\n",
    "#     y_pred = net.predict(xk_test)\n",
    "#     acc = metrics.accuracy_score(yk_test, y_pred)\n",
    "#     accuracies.append(acc)\n",
    "#     print('FinalAccuracy %.4f' % (np.mean(accuracies)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking accuracy on test set\n",
      "Got 159 / 375 correct (42.40)\n"
     ]
    }
   ],
   "source": [
    "#Check Test set\n",
    "check_accuracy(loader_test, model1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
