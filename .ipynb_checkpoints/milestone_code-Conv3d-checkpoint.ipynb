{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import sampler\n",
    "import skorch\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as T\n",
    "import torchvision.models as models\n",
    "import collections\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "# matplotlib.use('agg')\n",
    "import matplotlib.pyplot as plt\n",
    "from Lung_dataset import ILDDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using device: cuda\n"
     ]
    }
   ],
   "source": [
    "USE_GPU = True\n",
    "\n",
    "dtype = torch.float32 # we will be using float throughout this tutorial\n",
    "\n",
    "if USE_GPU and torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "# Constant to control how frequently we print train loss\n",
    "print_every = 100\n",
    "\n",
    "print('using device:', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_TOTAL = 1968\n",
    "NUM_TRAIN = 1600\n",
    "\n",
    "#add path as absolute path for root dir\n",
    "\n",
    "im_size = 128\n",
    "\n",
    "lung_dataset_train = ILDDataset(csv_file=r'C:/Users/Akrofi/Desktop/CS 231/Project/train_labels.csv', \n",
    "                          root_dir=r'C:/Users/Akrofi/Desktop/CS 231/Project/train',mask=True, train=True, resize=im_size)#, transform=transform)\n",
    "\n",
    "\n",
    "#add path as absolute path for root dir\n",
    "lung_dataset_test = ILDDataset(csv_file=r'C:/Users/Akrofi/Desktop/CS 231/Project/test_labels.csv', \n",
    "                          root_dir=r'C:/Users/Akrofi/Desktop/CS 231/Project/test', mask=True, train=False, resize=im_size)#, transform=transform)\n",
    "\n",
    "\n",
    "loader_train = DataLoader(lung_dataset_train, batch_size=16, sampler=sampler.SequentialSampler(range(NUM_TOTAL-NUM_TRAIN, NUM_TOTAL)))\n",
    "\n",
    "loader_val = DataLoader(lung_dataset_train, batch_size=16, \n",
    "                          sampler=sampler.SequentialSampler(range(NUM_TOTAL-NUM_TRAIN)))\n",
    "\n",
    "loader_test = DataLoader(lung_dataset_test, batch_size=16, \n",
    "                         sampler=sampler.SequentialSampler(range(336)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQUAAAD8CAYAAAB+fLH0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x20c24cb15f8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label: 2\n"
     ]
    }
   ],
   "source": [
    "#show datasample\n",
    "sample = lung_dataset_train[120]\n",
    "plt.imshow(sample[0], cmap='gray')\n",
    "plt.show()\n",
    "print(\"label: \" + str(sample[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def flatten(x):\n",
    "    N = x.shape[0] # read in N, C, H, W\n",
    "    return x.view(N, -1)  # \"flatten\" the C * H * W values into a single vector per image\n",
    "\n",
    "class Flatten(nn.Module):\n",
    "    def forward(self, x):\n",
    "        return flatten(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model():\n",
    "    \"\"\"\n",
    "    Used to fetch model for classification\n",
    "    \"\"\"\n",
    "      \n",
    "    in_channel = 1\n",
    "    channel_1 = 32\n",
    "    channel_2 = 64\n",
    "    channel_3 = 32\n",
    "    num_classes = 3\n",
    "\n",
    "    model = nn.Sequential(\n",
    "    nn.Conv3d(in_channel,channel_1, kernel_size=5, padding=2, stride= 1 ),\n",
    "    nn.ReLU(),\n",
    "    nn.Conv3d(channel_1, channel_2, kernel_size=3, padding=1, stride=1),\n",
    "    nn.ReLU(),\n",
    "    nn.BatchNorm3d(num_features= channel_2),\n",
    "    nn.MaxPool3d(kernel_size=1,stride=1),\n",
    "    nn.Conv3d(channel_2, channel_3, kernel_size=3, padding=1, stride=1),\n",
    "    nn.ReLU(),\n",
    "    Flatten(),\n",
    "    nn.Linear(2097152, num_classes)\n",
    ")\n",
    "\n",
    "    \n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def check_accuracy(loader, model, train=False):\n",
    "    if loader.dataset.train and train == True:\n",
    "        print('Checking accuracy on training set')\n",
    "    elif loader.dataset.train:\n",
    "        print('Checking accuracy on validation set')\n",
    "    else:\n",
    "        print('Checking accuracy on test set')   \n",
    "    num_correct = 0\n",
    "    num_samples = 0\n",
    "    model.eval()  # set model to evaluation mode\n",
    "    with torch.no_grad():\n",
    "        for x, y in loader:\n",
    "            x = x.to(device=device, dtype=dtype)  # move to device, e.g. GPU\n",
    "            y = y.to(device=device, dtype=torch.long)\n",
    "            \n",
    "            [N,H,W] =  [*x.size()]\n",
    "            \n",
    "#             print(y)\n",
    "            a = np.split(y,4)\n",
    "            y = np.zeros(len(a))\n",
    "            for i in range(len(a)):\n",
    "                b = collections.Counter(a[i]).most_common()[0][0]\n",
    "                y[i] = (b)\n",
    "           \n",
    "            y = torch.LongTensor(y)\n",
    "            y = y.to(device=device, dtype=torch.long)\n",
    "\n",
    "                                \n",
    "            scores = model(x.view(4, 1 , 4, H , W))\n",
    "            _, preds = scores.max(1)\n",
    "            num_correct += (preds == y).sum()\n",
    "            num_samples += preds.size(0)\n",
    "        acc = float(num_correct) / num_samples      \n",
    "        print('Got %d / %d correct (%.2f)' % (num_correct, num_samples, 100 * acc))\n",
    "        \n",
    "    return acc\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train(model, optimizer, epochs=1, overfit=False):\n",
    "    \"\"\"\n",
    "    Inputs:\n",
    "    - model: A PyTorch Module giving the model to train.\n",
    "    - optimizer: An Optimizer object we will use to train the model\n",
    "    - epochs: (Optional) A Python integer giving the number of epochs to train for\n",
    "    \n",
    "    Returns: Nothing, but prints model accuracies during training.\n",
    "    \"\"\"\n",
    "    model = model.to(device=device)  # move the model parameters to CPU/GPU\n",
    "    best_acc = 0;\n",
    "    for e in range(epochs):\n",
    "        for t, (x, y) in enumerate(loader_train):\n",
    "            model.train()  # put model to training mode\n",
    "            x = x.to(device=device, dtype=dtype)  # move to device, e.g. GPU\n",
    "            y = y.to(device=device, dtype=torch.long)\n",
    "            \n",
    "            [N,H,W] =  [*x.size()]\n",
    "            \n",
    "#             print(y)\n",
    "            a = np.split(y,4)\n",
    "            y = np.zeros(len(a))\n",
    "            for i in range(len(a)):\n",
    "                b = collections.Counter(a[i]).most_common()[0][0]\n",
    "                y[i] = b\n",
    "           \n",
    "            y = torch.LongTensor(y)\n",
    "            y = y.to(device=device, dtype=torch.long)\n",
    "            \n",
    "            \n",
    "            \n",
    "            scores = model(x.view(4, 1, 4, H , W))\n",
    "            Loss = nn.CrossEntropyLoss()\n",
    "            loss = Loss(scores, y)\n",
    "            \n",
    "            \n",
    "            reg = torch.tensor(1e-2, device= device, dtype=dtype)\n",
    "            l2_reg = torch.tensor(0. , device= device, dtype=dtype)\n",
    "            for param in model.parameters():\n",
    "                l2_reg += torch.norm(param)\n",
    "            loss += reg * l2_reg\n",
    "\n",
    "            # Zero out all of the gradients for the variables which the optimizer\n",
    "            # will update.\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # This is the backwards pass: compute the gradient of the loss with\n",
    "            # respect to each  parameter of the model.\n",
    "            loss.backward()\n",
    "\n",
    "            # Actually update the parameters of the model using the gradients\n",
    "            # computed by the backwards pass.\n",
    "            optimizer.step()\n",
    "            \n",
    "#             if t % print_every == 0:\n",
    "        print('Iteration %d, loss = %.4f' % (t, loss.item()))\n",
    "        if(overfit):\n",
    "            _ = check_accuracy(loader_train, model, train=True)\n",
    "        acc = check_accuracy(loader_val, model)\n",
    "        if acc > best_acc:\n",
    "                best_acc = acc\n",
    "                best_model = model\n",
    "        print()\n",
    "    return best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 99, loss = 2.4522\n",
      "Checking accuracy on training set\n",
      "Got 176 / 400 correct (44.00)\n",
      "Checking accuracy on validation set\n",
      "Got 15 / 92 correct (16.30)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model1 = get_model()\n",
    "optimizer = optim.Adam(model1.parameters(), lr = 0.001, weight_decay= 1e-4)\n",
    "best_model = train(model1, optimizer, epochs= 1, overfit=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking accuracy on test set\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-26-f180a6b52350>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#Check Test set\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mcheck_accuracy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloader_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbest_model\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-23-39cbd61d0f5c>\u001b[0m in \u001b[0;36mcheck_accuracy\u001b[1;34m(loader, model, train)\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# set model to evaluation mode\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m         \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mloader\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m             \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# move to device, e.g. GPU\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m             \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    262\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnum_workers\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# same-process loading\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    263\u001b[0m             \u001b[0mindices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msample_iter\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 264\u001b[1;33m             \u001b[0mbatch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    265\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    266\u001b[0m                 \u001b[0mbatch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpin_memory_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    262\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnum_workers\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# same-process loading\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    263\u001b[0m             \u001b[0mindices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msample_iter\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 264\u001b[1;33m             \u001b[0mbatch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    265\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    266\u001b[0m                 \u001b[0mbatch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpin_memory_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\GitHub\\cs231n_bmi260_project\\Lung_dataset.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, idx)\u001b[0m\n\u001b[0;32m     67\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     68\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0midx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 69\u001b[1;33m         \u001b[0mslice_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscan_num\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mslice_num\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscan_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mslice_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind_slice_path\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     70\u001b[0m         \u001b[0mmask_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind_mask_path\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscan_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mslice_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     71\u001b[0m         \u001b[0mds\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpydicom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mslice_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'NoneType' object is not iterable"
     ]
    }
   ],
   "source": [
    "#Check Test set\n",
    "check_accuracy(loader_test, best_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    " # Define model\n",
    "    \n",
    "   "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
