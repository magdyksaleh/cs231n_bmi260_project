{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import sampler\n",
    "import skorch\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as T\n",
    "import torchvision.models as models\n",
    "import collections\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "# matplotlib.use('agg')\n",
    "import matplotlib.pyplot as plt\n",
    "from Lung_dataset import ILDDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using device: cuda\n"
     ]
    }
   ],
   "source": [
    "USE_GPU = True\n",
    "\n",
    "dtype = torch.float32 # we will be using float throughout this tutorial\n",
    "\n",
    "if USE_GPU and torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "# Constant to control how frequently we print train loss\n",
    "print_every = 100\n",
    "\n",
    "print('using device:', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "NUM_TOTAL = 1968\n",
    "NUM_TRAIN = 1600\n",
    "#add path as absolute path for root dir\n",
    "\n",
    "im_size = 128\n",
    "\n",
    "lung_dataset_train = ILDDataset(csv_file=r'C:/Users/Akrofi/Desktop/CS 231/Project/train_labels.csv', \n",
    "                          root_dir=r'C:/Users/Akrofi/Desktop/CS 231/Project/train',mask=True, train=True, resize=im_size)#, transform=transform)\n",
    "\n",
    "\n",
    "#add path as absolute path for root dir\n",
    "lung_dataset_test = ILDDataset(csv_file=r'C:/Users/Akrofi/Desktop/CS 231/Project/test_labels.csv', \n",
    "                          root_dir=r'C:/Users/Akrofi/Desktop/CS 231/Project/test', mask=True, train=False, resize=im_size)#, transform=transform)\n",
    "\n",
    "\n",
    "loader_train = DataLoader(lung_dataset_train, batch_size=4, \n",
    "                          sampler=sampler.SubsetRandomSampler(range(NUM_TRAIN)))\n",
    "\n",
    "loader_val = DataLoader(lung_dataset_train, batch_size=4, \n",
    "                          sampler=sampler.SubsetRandomSampler(range(NUM_TRAIN, NUM_TOTAL)))\n",
    "\n",
    "loader_test = DataLoader(lung_dataset_test, batch_size=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQUAAAD8CAYAAAB+fLH0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4wLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvpW3flQAADtRJREFUeJzt3X+s3XV9x/Hna60oYAhULk1tca1J\n44+ZOcgNA12IEYngjGWJP6g4G6k2S9jEH4nS+QfZX0pmEDUO1gizm1hkyEZDnI5UjNkfdt6qQaBi\nO3BQqfQaBRdNNjrf++N8K/fT3ebWe875nlt5PpLmnO/nfL7n++bTw4vP93u+nE+qCkk64ncmXYCk\npcVQkNQwFCQ1DAVJDUNBUsNQkNQwFCQ1xhYKSS5J8lCS/UmuGddxJI1WxnHzUpJlwA+Ai4EDwLeA\njVX14MgPJmmklo/pfc8D9lfVwwBJbgM2APOGwplnnllr164dUymSAPbs2fOTqppaqN+4QmE18Nic\n7QPAH87tkGQLsAXgRS96ETMzM2MqRRJAkv88nn7juqaQedqa85Sq2lZV01U1PTW1YHhJ6sm4QuEA\ncPac7TXA42M6lqQRGlcofAtYn2RdkpOAy4GdYzqWpBEayzWFqjqc5M+BrwLLgFuq6oFxHEvSaI3r\nQiNV9WXgy+N6f0nj4R2NkhqGgqSGoSCpYShIahgKkhqGgqSGoSCpYShIahgKkhqGgqSGoSCpYShI\nahgKkhqGgqSGoSCpYShIahgKkhqGgqSGoSCpYShIahgKkhqGgqSGoSCpYShIahgKkhqLDoUkZye5\nN8neJA8kubprX5HkniT7usczRleupHEbZqZwGPhgVb0MOB+4KsnLgWuAXVW1HtjVbUs6QSw6FKrq\nYFV9u3v+X8BeYDWwAdjeddsOXDZskZL6M5JrCknWAucAu4GVVXUQBsEBnHWMfbYkmUkyMzs7O4oy\nJI3A0KGQ5PnAl4D3VdXPj3e/qtpWVdNVNT01NTVsGZJGZKhQSPIcBoFwa1Xd2TU/kWRV9/oq4NBw\nJUrq0zDfPgS4GdhbVdfPeWknsKl7vgm4a/HlSerb8iH2fTXwp8D3kny3a/tL4GPA7Uk2A48Cbxmu\nREl9WnQoVNW/ATnGyxct9n0lTZZ3NEpqGAqSGoaCpIahIKlhKEhqGAqSGoaCpIahIKlhKEhqGAqS\nGoaCpIahIKlhKEhqGAqSGoaCpIahIKlhKEhqGAqSGoaCpIahIKlhKEhqGAqSGoaCpIahIKkxigVm\nlyX5TpK7u+11SXYn2Zfki0lOGr5MSX0ZxUzhamDvnO3rgE9U1XrgZ8DmERxDUk+GXXV6DfDHwGe7\n7QCvBe7oumwHLhvmGJL6NexM4QbgQ8Cvuu0XAE9W1eFu+wCweshjSOrRMEvRvxE4VFV75jbP07WO\nsf+WJDNJZmZnZxdbhqQRG2am8GrgTUl+CNzG4LThBuD0JEdWs14DPD7fzlW1raqmq2p6ampqiDIk\njdKiQ6GqtlbVmqpaC1wOfK2qrgDuBd7cddsE3DV0lZJ6M477FD4MfCDJfgbXGG4ewzEkjcnyhbss\nrKq+Dny9e/4wcN4o3ldS/7yjUVLDUJDUMBQkNQwFSQ1DQVLDUJDUMBQkNQwFSQ1DQVLDUJDUMBQk\nNQwFSQ1DQVLDUJDUMBQkNQwFSQ1DQVLDUJDUMBQkNQwFSQ1DQVLDUJDUMBQkNQwFSQ1DQVJjqFBI\ncnqSO5J8P8neJBckWZHkniT7usczRlWspPEbdqbwSeArVfVS4JXAXuAaYFdVrQd2dduSThCLDoUk\npwEX0i0gW1X/U1VPAhuA7V237cBlwxYpqT/DzBReDMwCf5fkO0k+m+RUYGVVHQToHs8aQZ2SejJM\nKCwHzgVurKpzgF/wG5wqJNmSZCbJzOzs7BBlSBqlYULhAHCgqnZ323cwCIknkqwC6B4PzbdzVW2r\nqumqmp6amhqiDEmjtOhQqKofA48leUnXdBHwILAT2NS1bQLuGqpCSb1aPuT+fwHcmuQk4GHgXQyC\n5vYkm4FHgbcMeQxJPRoqFKrqu8D0PC9dNMz7Spoc72iU1DAUJDUMBUkNQ0FSw1CQ1DAUJDUMBUkN\nQ0FSw1CQ1DAUJDUMBUkNQ0FSw1CQ1DAUJDUMBUkNQ0FSw1CQ1DAUJDUMBUkNQ0FSw1CQ1DAUJDUM\nBUkNQ0FSw1CQ1BgqFJK8P8kDSe5PsiPJ85KsS7I7yb4kX+yWlJN0glh0KCRZDbwXmK6qVwDLgMuB\n64BPVNV64GfA5lEUKqkfw54+LAdOTrIcOAU4CLyWwbL0ANuBy4Y8hqQeDbMU/Y+AjzNYWfog8BSw\nB3iyqg533Q4Aq4ctUlJ/hjl9OAPYAKwDXgicClw6T9c6xv5bkswkmZmdnV1sGZJGbJjTh9cBj1TV\nbFU9DdwJvAo4vTudAFgDPD7fzlW1raqmq2p6ampqiDIkjdIwofAocH6SU5IEuAh4ELgXeHPXZxNw\n13AlSurTMNcUdjO4oPht4Hvde20DPgx8IMl+4AXAzSOoU1JPli/c5diq6lrg2qOaHwbOG+Z91Z8d\nO3YAsHHjxglXoqXCOxolNYaaKejEd/DgwUmXoCXGmYKkhjOFZ7nTTjtt0iVoiTEUnuXe/e53T7oE\nAD760Y8CsHXr1glXIk8fJDWcKWhJcIawdDhTkNQwFCQ1DAVJDUNBUsNQkNQwFCQ1/EpyCF/4whcA\nWLZsGW9729smXI00Gs4UJDWcKQzh7W9/OwCzs7PccsstAFx55ZWTLEkamqEwAlNTU1x44YUAvPWt\nbwXgPe95DxdffPEky5IWxdMHSY1UzfsL7L2anp6umZmZSZcxUtdffz1PP/00ACtWrADg5JNPBuAd\n73jHxOrSs1eSPVU1vVA/ZwqSGs4UejD4BXxYvnxwCWflypVcccUVAFx33XUTq0vPLsc7U/BCYw+O\nBO/nP//5Xz9++tOfBp75jcRTTjmFm266aTIFSnN4+iCp4emD9CzhhUZJi7JgKCS5JcmhJPfPaVuR\n5J4k+7rHM7r2JPlUkv1J7kty7jiLlzR6xzNT+BxwyVFt1wC7qmo9sKvbhsFS9Ou7P1uAG0dTpqS+\nLBgKVfUN4KdHNW8AtnfPtwOXzWn/+xr4JoNl6VeNqlhJ47fYaworq+ogQPd4Vte+GnhsTr8DXZuk\nE8SoLzRmnrZ5v95IsiXJTJKZ2dnZEZchabEWGwpPHDkt6B4Pde0HgLPn9FsDPD7fG1TVtqqarqrp\nqampRZYhadQWGwo7gU3d803AXXPa39l9C3E+8NSR0wxJJ4YFb3NOsgN4DXBmkgPAtcDHgNuTbAYe\nBd7Sdf8y8AZgP/BL4F1jqFnSGC0YClW18RgvXTRP3wKuGrYoSZPjHY2SGoaCpIahIKlhKEhqGAqS\nGoaCpIahIKlhKEhqGAqSGoaCpIahIKlhKEhqGAqSGoaCpIahIKlhKEhqGAqSGoaCpIahIKlhKEhq\nGAqSGoaCpIahIKlhKEhqGAqSGguGQpJbkhxKcv+ctr9O8v0k9yX5pySnz3lta5L9SR5K8vpxFS5p\nPI5npvA54JKj2u4BXlFVvw/8ANgKkOTlwOXA73X7/E2SZSOrVtLYLRgKVfUN4KdHtf1rVR3uNr/J\nYMl5gA3AbVX131X1CIOFZs8bYb2SxmwU1xSuBP6le74aeGzOawe6NkkniKFCIclHgMPArUea5ulW\nx9h3S5KZJDOzs7PDlCFphBYdCkk2AW8EruiWoIfBzODsOd3WAI/Pt39Vbauq6aqanpqaWmwZkkZs\nUaGQ5BLgw8CbquqXc17aCVye5LlJ1gHrgX8fvkxJfVm+UIckO4DXAGcmOQBcy+DbhucC9yQB+GZV\n/VlVPZDkduBBBqcVV1XV/46reEmjl2dm/pMzPT1dMzMzky5D+q2WZE9VTS/UzzsaJTUMBUkNQ0FS\nw1CQ1DAUJDUMBUkNQ0FSw1CQ1FgSNy8lmQV+Afxk0rUAZ2Idc1lH60Su43erasH/0WhJhAJAkpnj\nudvKOqzDOsZbh6cPkhqGgqTGUgqFbZMuoGMdLeto/dbXsWSuKUhaGpbSTEHSErAkQiHJJd06EfuT\nXNPTMc9Ocm+SvUkeSHJ1174iyT1J9nWPZ/RUz7Ik30lyd7e9Lsnuro4vJjmphxpOT3JHt6bH3iQX\nTGI8kry/+zu5P8mOJM/razyOsc7JvGOQgU91n9v7kpw75jp6WW9l4qHQrQvxGeBS4OXAxm79iHE7\nDHywql4GnA9c1R33GmBXVa0HdnXbfbga2Dtn+zrgE10dPwM291DDJ4GvVNVLgVd29fQ6HklWA+8F\npqvqFcAyBmuJ9DUen+P/r3NyrDG4lMFPDq4HtgA3jrmOftZbqaqJ/gEuAL46Z3srsHUCddwFXAw8\nBKzq2lYBD/Vw7DUMPmyvBe5m8KvYPwGWzzdGY6rhNOARuutMc9p7HQ+eWSZgBYOfC7wbeH2f4wGs\nBe5faAyAvwU2ztdvHHUc9dqfALd2z5t/Z4CvAhcs9rgTnymwBNaKSLIWOAfYDaysqoMA3eNZPZRw\nA/Ah4Ffd9guAJ+uZBXf6GJMXA7PA33WnMZ9Ncio9j0dV/Qj4OPAocBB4CthD/+Mx17HGYJKf3bGt\nt7IUQuG414oYy8GT5wNfAt5XVT/v67hzjv9G4FBV7ZnbPE/XcY/JcuBc4MaqOofBbed9nTr9Wne+\nvgFYB7wQOJXBNP1oS+Frs4l8dodZb+V4LIVQOO61IkYtyXMYBMKtVXVn1/xEklXd66uAQ2Mu49XA\nm5L8ELiNwSnEDcDpSY782nYfY3IAOFBVu7vtOxiERN/j8TrgkaqaraqngTuBV9H/eMx1rDHo/bM7\n7Horx2MphMK3gPXd1eWTGFww2Tnug2bw2/Q3A3ur6vo5L+0ENnXPNzG41jA2VbW1qtZU1VoG/+xf\nq6orgHuBN/dYx4+Bx5K8pGu6iMFP9fc6HgxOG85Pckr3d3Skjl7H4yjHGoOdwDu7byHOB546cpox\nDr2ttzLOi0a/wQWVNzC4mvofwEd6OuYfMZhi3Qd8t/vzBgbn87uAfd3jih7H4TXA3d3zF3d/sfuB\nfwSe28Px/wCY6cbkn4EzJjEewF8B3wfuB/6BwRojvYwHsIPBtYynGfwXePOxxoDBtP0z3ef2ewy+\nMRlnHfsZXDs48nm9aU7/j3R1PARcOsyxvaNRUmMpnD5IWkIMBUkNQ0FSw1CQ1DAUJDUMBUkNQ0FS\nw1CQ1Pg/3MG+nV60N0MAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x238700bbb70>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label: 1\n"
     ]
    }
   ],
   "source": [
    "#show datasample\n",
    "sample = lung_dataset_train[120]\n",
    "plt.imshow(sample[0], cmap='gray')\n",
    "plt.show()\n",
    "print(\"label: \" + str(sample[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def flatten(x):\n",
    "    N = x.shape[0] # read in N, C, H, W\n",
    "    return x.view(N, -1)  # \"flatten\" the C * H * W values into a single vector per image\n",
    "\n",
    "class Flatten(nn.Module):\n",
    "    def forward(self, x):\n",
    "        return flatten(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model():\n",
    "    \"\"\"\n",
    "    Used to fetch model for classification\n",
    "    \"\"\"\n",
    "      \n",
    "    in_channel = 1\n",
    "    channel_1 = 32\n",
    "    channel_2 = 64\n",
    "    channel_3 = 32\n",
    "    num_classes = 3\n",
    "\n",
    "    model = nn.Sequential(\n",
    "    nn.Conv3d(in_channel,channel_1, kernel_size=5, padding=2, stride= 1 ),\n",
    "    nn.ReLU(),\n",
    "    nn.Conv3d(channel_1, channel_2, kernel_size=3, padding=1, stride=1),\n",
    "    nn.ReLU(),\n",
    "    nn.BatchNorm3d(num_features= channel_2),\n",
    "    nn.MaxPool3d(kernel_size=1,stride=1),\n",
    "    nn.Conv3d(channel_2, channel_3, kernel_size=3, padding=1, stride=1),\n",
    "    nn.ReLU(),\n",
    "    Flatten(),\n",
    "    nn.Linear(2097152, num_classes)\n",
    ")\n",
    "\n",
    "    \n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def check_accuracy(loader, model, train=False):\n",
    "    if loader.dataset.train and train == True:\n",
    "        print('Checking accuracy on training set')\n",
    "    elif loader.dataset.train:\n",
    "        print('Checking accuracy on validation set')\n",
    "    else:\n",
    "        print('Checking accuracy on test set')   \n",
    "    num_correct = 0\n",
    "    num_samples = 0\n",
    "    model.eval()  # set model to evaluation mode\n",
    "    with torch.no_grad():\n",
    "        for x, y in loader:\n",
    "            x = x.to(device=device, dtype=dtype)  # move to device, e.g. GPU\n",
    "            y = y.to(device=device, dtype=torch.long)\n",
    "            \n",
    "            [N,H,W] =  [*x.size()]\n",
    "            \n",
    "            \n",
    "            a = collections.Counter(y).most_common()[0][0]\n",
    "            y = torch.LongTensor([a])\n",
    "            y = y.to(device=device, dtype=torch.long)\n",
    "\n",
    "                                \n",
    "            scores = model(x.view(1, 1, N, H , W))\n",
    "            _, preds = scores.max(1)\n",
    "            num_correct += (preds == y).sum()\n",
    "            num_samples += preds.size(0)\n",
    "        acc = float(num_correct) / num_samples      \n",
    "        print('Got %d / %d correct (%.2f)' % (num_correct, num_samples, 100 * acc))\n",
    "        \n",
    "    return acc\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train(model, optimizer, epochs=1, overfit=False):\n",
    "    \"\"\"\n",
    "    Inputs:\n",
    "    - model: A PyTorch Module giving the model to train.\n",
    "    - optimizer: An Optimizer object we will use to train the model\n",
    "    - epochs: (Optional) A Python integer giving the number of epochs to train for\n",
    "    \n",
    "    Returns: Nothing, but prints model accuracies during training.\n",
    "    \"\"\"\n",
    "    model = model.to(device=device)  # move the model parameters to CPU/GPU\n",
    "    best_acc = 0;\n",
    "    for e in range(epochs):\n",
    "        for t, (x, y) in enumerate(loader_train):\n",
    "            model.train()  # put model to training mode\n",
    "            x = x.to(device=device, dtype=dtype)  # move to device, e.g. GPU\n",
    "            y = y.to(device=device, dtype=torch.long)\n",
    "            \n",
    "            [N,H,W] =  [*x.size()]\n",
    "            \n",
    "            \n",
    "            a = collections.Counter(y).most_common()[0][0]\n",
    "            y = torch.LongTensor([a])\n",
    "            y = y.to(device=device, dtype=torch.long)\n",
    "            \n",
    "            \n",
    "            scores = model(x.view(1, 1, N, H , W))\n",
    "            Loss = nn.CrossEntropyLoss()\n",
    "            loss = Loss(scores, y)\n",
    "            \n",
    "            \n",
    "            reg = torch.tensor(1e-3, device= device, dtype=dtype)\n",
    "            l2_reg = torch.tensor(0. , device= device, dtype=dtype)\n",
    "            for param in model.parameters():\n",
    "                l2_reg += torch.norm(param)\n",
    "            loss += reg * l2_reg\n",
    "\n",
    "            # Zero out all of the gradients for the variables which the optimizer\n",
    "            # will update.\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # This is the backwards pass: compute the gradient of the loss with\n",
    "            # respect to each  parameter of the model.\n",
    "            loss.backward()\n",
    "\n",
    "            # Actually update the parameters of the model using the gradients\n",
    "            # computed by the backwards pass.\n",
    "            optimizer.step()\n",
    "            \n",
    "#             if t % print_every == 0:\n",
    "        print('Iteration %d, loss = %.4f' % (t, loss.item()))\n",
    "        if(overfit):\n",
    "            _ = check_accuracy(loader_train, model, train=True)\n",
    "        acc = check_accuracy(loader_val, model)\n",
    "        if acc > best_acc:\n",
    "                best_acc = acc\n",
    "                best_model = model\n",
    "        print()\n",
    "    return best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "size mismatch, m1: [1 x 2097152], m2: [1048576 x 3] at c:\\programdata\\miniconda3\\conda-bld\\pytorch_1524549877902\\work\\aten\\src\\thc\\generic/THCTensorMathBlas.cu:249",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-20-7a45b54d537d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mmodel1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moptim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.001\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight_decay\u001b[0m\u001b[1;33m=\u001b[0m \u001b[1;36m1e-4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mbest_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moverfit\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-19-c883945f095b>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(model, optimizer, epochs, overfit)\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m             \u001b[0mscores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mN\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mH\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0mW\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     27\u001b[0m             \u001b[0mLoss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCrossEntropyLoss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m             \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLoss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    489\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    490\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 491\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    492\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    493\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\container.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m     89\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     90\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 91\u001b[1;33m             \u001b[0minput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     92\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    489\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    490\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 491\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    492\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    493\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\linear.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 55\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     56\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36mlinear\u001b[1;34m(input, weight, bias)\u001b[0m\n\u001b[0;32m    990\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m2\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mbias\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    991\u001b[0m         \u001b[1;31m# fused op is marginally faster\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 992\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    993\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    994\u001b[0m     \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: size mismatch, m1: [1 x 2097152], m2: [1048576 x 3] at c:\\programdata\\miniconda3\\conda-bld\\pytorch_1524549877902\\work\\aten\\src\\thc\\generic/THCTensorMathBlas.cu:249"
     ]
    }
   ],
   "source": [
    "model1 = get_model()\n",
    "optimizer = optim.Adam(model1.parameters(), lr = 0.001, weight_decay= 1e-4)\n",
    "best_model = train(model1, optimizer, epochs=10, overfit=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check Test set\n",
    "check_accuracy(loader_test, best_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    " # Define model\n",
    "    \n",
    "   "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
