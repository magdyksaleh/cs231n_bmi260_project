{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import sampler\n",
    "import skorch\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as T\n",
    "import torchvision.models as models\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "matplotlib.use('agg')\n",
    "import matplotlib.pyplot as plt\n",
    "from Lung_dataset import ILDDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using device: cpu\n"
     ]
    }
   ],
   "source": [
    "USE_GPU = True\n",
    "\n",
    "dtype = torch.float32 # we will be using float throughout this tutorial\n",
    "\n",
    "if USE_GPU and torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "# Constant to control how frequently we print train loss\n",
    "print_every = 100\n",
    "\n",
    "print('using device:', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "NUM_TOTAL = 1982\n",
    "NUM_TRAIN = 1500\n",
    "#add path as absolute path for root dir\n",
    "lung_dataset_train = ILDDataset(csv_file='../Clean_train_test_dataset/Dataset/train_labels.csv', \n",
    "                          root_dir='../Clean_train_test_dataset/Dataset/train',mask=True, train=True)#, transform=transform)\n",
    "\n",
    "\n",
    "#add path as absolute path for root dir\n",
    "lung_dataset_test = ILDDataset(csv_file='../Clean_train_test_dataset/Dataset/test_labels.csv', \n",
    "                          root_dir='../Clean_train_test_dataset/Dataset/test/', mask=True, train=False)#, transform=transform)\n",
    "\n",
    "\n",
    "loader_train = DataLoader(lung_dataset_train, batch_size=32, \n",
    "                          sampler=sampler.SubsetRandomSampler(range(NUM_TRAIN)))\n",
    "\n",
    "loader_val = DataLoader(lung_dataset_train, batch_size=32, \n",
    "                          sampler=sampler.SubsetRandomSampler(range(NUM_TRAIN, NUM_TOTAL)))\n",
    "\n",
    "loader_test = DataLoader(lung_dataset_test, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label: 2\n"
     ]
<<<<<<< HEAD
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11cb00f98>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
=======
>>>>>>> a11e9c36cf4bfb29af405865476a08e97152236f
    }
   ],
   "source": [
    "#show datasample\n",
    "sample = lung_dataset_train[127]\n",
    "plt.imshow(sample[0], cmap='gray')\n",
    "print(\"label: \" + str(sample[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def flatten(x):\n",
    "    N = x.shape[0] # read in N, C, H, W\n",
    "    return x.view(N, -1)  # \"flatten\" the C * H * W values into a single vector per image\n",
    "\n",
    "class Flatten(nn.Module):\n",
    "    def forward(self, x):\n",
    "        return flatten(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "channel_1 = 64\n",
    "channel_2 = 64\n",
    "channel_3 = 128\n",
    "\n",
    "learning_rate = 2.5e-3\n",
    "\n",
    "in_channel = 62\n",
    "num_classes = 3\n",
    "\n",
    "# model = nn.Sequential(\n",
    "#     nn.Conv2d(in_channel, channel_1, 5, padding=2),\n",
    "#     nn.BatchNorm2d(channel_1),\n",
    "#     nn.ReLU(),\n",
    "#     nn.Conv2d(channel_1, channel_2, 3, padding=1),\n",
    "#     nn.BatchNorm2d(channel_2),\n",
    "#     nn.ReLU(),\n",
    "#     nn.MaxPool2d(2),\n",
    "#     Flatten(),\n",
    "#     nn.Linear((32*512*512)/2, num_classes)\n",
    "# )\n",
    "# model = model.to(device=device)\n",
    "\n",
    "model = models.resnet50(pretrained=True)\n",
    "model.avgpool = nn.AvgPool2d(1, stride=1)\n",
    "model.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=1, bias=False)\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "model.fc = nn.Linear(8192, num_classes)\n",
    "\n",
    "# from skorch import NeuralNetClassifier\n",
    "\n",
    "# net = NeuralNetClassifier(\n",
    "#     module=model,\n",
    "#     criterion = nn.CrossEntropyLoss,\n",
    "#     optimizer=optim.Adam,\n",
    "#     train_split=None,\n",
    "#     max_epochs=5,\n",
    "#     lr = learning_rate,\n",
    "#     warm_start = True,\n",
    "#     device = device\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def check_accuracy_part34(loader, model):\n",
    "    if loader.dataset.train:\n",
    "        print('Checking accuracy on validation set')\n",
    "    else:\n",
    "        print('Checking accuracy on test set')   \n",
    "    num_correct = 0\n",
    "    num_samples = 0\n",
    "    model.eval()  # set model to evaluation mode\n",
    "    with torch.no_grad():\n",
    "        for x, y in loader:\n",
    "            x = x.to(device=device, dtype=dtype)  # move to device, e.g. GPU\n",
    "            x.unsqueeze_(1)\n",
    "            y = y.to(device=device, dtype=torch.long)\n",
    "            scores = model(x)\n",
    "            _, preds = scores.max(1)\n",
    "            num_correct += (preds == y).sum()\n",
    "            num_samples += preds.size(0)\n",
    "        acc = float(num_correct) / num_samples\n",
    "        print('Got %d / %d correct (%.2f)' % (num_correct, num_samples, 100 * acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def train_part34(model, optimizer, epochs=1):\n",
    "    \"\"\"\n",
    "    Train a model on CIFAR-10 using the PyTorch Module API.\n",
    "    \n",
    "    Inputs:\n",
    "    - model: A PyTorch Module giving the model to train.\n",
    "    - optimizer: An Optimizer object we will use to train the model\n",
    "    - epochs: (Optional) A Python integer giving the number of epochs to train for\n",
    "    \n",
    "    Returns: Nothing, but prints model accuracies during training.\n",
    "    \"\"\"\n",
    "    model = model.to(device=device)  # move the model parameters to CPU/GPU\n",
    "    for e in range(epochs):\n",
    "        for t, (x, y) in enumerate(loader_train):\n",
    "            model.train()  # put model to training mode\n",
    "            x = x.to(device=device, dtype=dtype)  # move to device, e.g. GPU\n",
    "            y = y.to(device=device, dtype=torch.long)\n",
    "            \n",
    "            x.unsqueeze_(1)\n",
    "            scores = model(x)\n",
    "            loss = F.cross_entropy(scores, y)\n",
    "\n",
    "            # Zero out all of the gradients for the variables which the optimizer\n",
    "            # will update.\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # This is the backwards pass: compute the gradient of the loss with\n",
    "            # respect to each  parameter of the model.\n",
    "            loss.backward()\n",
    "\n",
    "            # Actually update the parameters of the model using the gradients\n",
    "            # computed by the backwards pass.\n",
    "            optimizer.step()\n",
    "            \n",
    "#             if e==0 and t==0:\n",
    "#                 print('Initial loss = %.4f' % (loss.item()))\n",
    "#                 check_accuracy_part34(loader_val, model)\n",
    "#                 print()\n",
    "\n",
    "            if t % print_every == 0:\n",
    "                print('Iteration %d, loss = %.4f' % (t, loss.item()))\n",
    "                check_accuracy_part34(loader_train, model)\n",
    "                check_accuracy_part34(loader_val, model)\n",
    "                print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0, loss = 1.0668\n",
      "Checking accuracy on validation set\n",
      "Got 634 / 1500 correct (42.27)\n",
      "Checking accuracy on validation set\n",
      "Got 309 / 482 correct (64.11)\n",
      "\n",
      "Iteration 0, loss = 1.0165\n",
      "Checking accuracy on validation set\n",
      "Got 873 / 1500 correct (58.20)\n",
      "Checking accuracy on validation set\n",
      "Got 293 / 482 correct (60.79)\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-515b2e129fa3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequires_grad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.001\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# optimizer = optim.SGD(filter(lambda p: p.requires_grad, model.parameters()), lr = 0.01, momentum=0.9)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtrain_part34\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-8-c2f6d1437424>\u001b[0m in \u001b[0;36mtrain_part34\u001b[0;34m(model, optimizer, epochs)\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0;31m# This is the backwards pass: compute the gradient of the loss with\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m             \u001b[0;31m# respect to each  parameter of the model.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m             \u001b[0;31m# Actually update the parameters of the model using the gradients\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/cs231n/lib/python3.6/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m     91\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m         \"\"\"\n\u001b[0;32m---> 93\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/cs231n/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     87\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     88\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "optimizer = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr = 0.001)\n",
    "# optimizer = optim.SGD(filter(lambda p: p.requires_grad, model.parameters()), lr = 0.01, momentum=0.9)\n",
    "train_part34(model, optimizer, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import KFold\n",
    "# from sklearn import metrics\n",
    "\n",
    "# # for epoch in range(5):\n",
    "# kf = KFold(n_splits=3, shuffle = True)\n",
    "# accuracies=[]\n",
    "# for train_index, test_index in kf.split(x):\n",
    "#     accuracies=[]\n",
    "# #     (N, C1, C2, S) = x.shape \n",
    "# #     x = x.reshape((N, 62, 512, 512))\n",
    "# #     y = y.reshape((y.shape[0]))\n",
    "# #     print(x.shape)\n",
    "# #     print(y.shape)\n",
    "# #     print(train_index)\n",
    "# #     print(test_index)\n",
    "#     xk_train, xk_test = x[train_index], x[test_index]\n",
    "#     yk_train, yk_test = y[train_index], y[test_index]\n",
    "#     net.fit(xk_train,yk_train)\n",
    "#     y_pred = net.predict(xk_test)\n",
    "#     acc = metrics.accuracy_score(yk_test, y_pred)\n",
    "#     accuracies.append(acc)\n",
    "#     print('FinalAccuracy %.4f' % (np.mean(accuracies)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "(N, C1, C2, S) = x_Test.shape\n",
    "x_Test = x_Test.reshape((N, S, C1, C2))\n",
    "y_pred_test = net.predict(x_Test)\n",
    "acc = metrics.accuracy_score(y_Test, y_pred_test)\n",
    "print('TestAccuracy %.4f' % (acc))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
