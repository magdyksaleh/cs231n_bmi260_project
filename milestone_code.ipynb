{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import sampler\n",
    "import skorch\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as T\n",
    "import torchvision.models as models\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "matplotlib.use('agg')\n",
    "import matplotlib.pyplot as plt\n",
    "from Lung_dataset import ILDDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using device: cpu\n"
     ]
    }
   ],
   "source": [
    "USE_GPU = True\n",
    "\n",
    "dtype = torch.float32 # we will be using float throughout this tutorial\n",
    "\n",
    "if USE_GPU and torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "# Constant to control how frequently we print train loss\n",
    "print_every = 100\n",
    "\n",
    "print('using device:', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "NUM_TOTAL = 1982\n",
    "NUM_TRAIN = 1500\n",
    "#add path as absolute path for root dir\n",
    "lung_dataset_train = ILDDataset(csv_file='../Clean_train_test_dataset/Dataset/train_labels.csv', \n",
    "                          root_dir='../Clean_train_test_dataset/Dataset/train',mask=True, train=True)#, transform=transform)\n",
    "\n",
    "\n",
    "#add path as absolute path for root dir\n",
    "lung_dataset_test = ILDDataset(csv_file='../Clean_train_test_dataset/Dataset/test_labels.csv', \n",
    "                          root_dir='../Clean_train_test_dataset/Dataset/test/', mask=True, train=False)#, transform=transform)\n",
    "\n",
    "\n",
    "loader_train = DataLoader(lung_dataset_train, batch_size=32, \n",
    "                          sampler=sampler.SubsetRandomSampler(range(NUM_TRAIN)))\n",
    "\n",
    "loader_val = DataLoader(lung_dataset_train, batch_size=32, \n",
    "                          sampler=sampler.SubsetRandomSampler(range(NUM_TRAIN, NUM_TOTAL)))\n",
    "\n",
    "loader_test = DataLoader(lung_dataset_test, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label: 2\n"
     ]
    }
   ],
   "source": [
    "#show datasample\n",
    "sample = lung_dataset_train[127]\n",
    "plt.imshow(sample[0], cmap='gray')\n",
    "print(\"label: \" + str(sample[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def flatten(x):\n",
    "    N = x.shape[0] # read in N, C, H, W\n",
    "    return x.view(N, -1)  # \"flatten\" the C * H * W values into a single vector per image\n",
    "\n",
    "class Flatten(nn.Module):\n",
    "    def forward(self, x):\n",
    "        return flatten(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "channel_1 = 64\n",
    "channel_2 = 64\n",
    "channel_3 = 128\n",
    "\n",
    "learning_rate = 2.5e-3\n",
    "\n",
    "in_channel = 62\n",
    "num_classes = 3\n",
    "\n",
    "# model = nn.Sequential(\n",
    "#     nn.Conv2d(in_channel, channel_1, 5, padding=2),\n",
    "#     nn.BatchNorm2d(channel_1),\n",
    "#     nn.ReLU(),\n",
    "#     nn.Conv2d(channel_1, channel_2, 3, padding=1),\n",
    "#     nn.BatchNorm2d(channel_2),\n",
    "#     nn.ReLU(),\n",
    "#     nn.MaxPool2d(2),\n",
    "#     Flatten(),\n",
    "#     nn.Linear((32*512*512)/2, num_classes)\n",
    "# )\n",
    "# model = model.to(device=device)\n",
    "\n",
    "model = models.resnet50(pretrained=True)\n",
    "model.avgpool = nn.AvgPool2d(1, stride=1)\n",
    "model.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=1, bias=False)\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "model.fc = nn.Linear(8192, num_classes)\n",
    "\n",
    "# from skorch import NeuralNetClassifier\n",
    "\n",
    "# net = NeuralNetClassifier(\n",
    "#     module=model,\n",
    "#     criterion = nn.CrossEntropyLoss,\n",
    "#     optimizer=optim.Adam,\n",
    "#     train_split=None,\n",
    "#     max_epochs=5,\n",
    "#     lr = learning_rate,\n",
    "#     warm_start = True,\n",
    "#     device = device\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def check_accuracy_part34(loader, model):\n",
    "    if loader.dataset.train:\n",
    "        print('Checking accuracy on validation set')\n",
    "    else:\n",
    "        print('Checking accuracy on test set')   \n",
    "    num_correct = 0\n",
    "    num_samples = 0\n",
    "    model.eval()  # set model to evaluation mode\n",
    "    with torch.no_grad():\n",
    "        for x, y in loader:\n",
    "            x = x.to(device=device, dtype=dtype)  # move to device, e.g. GPU\n",
    "            x.unsqueeze_(1)\n",
    "            y = y.to(device=device, dtype=torch.long)\n",
    "            scores = model(x)\n",
    "            _, preds = scores.max(1)\n",
    "            num_correct += (preds == y).sum()\n",
    "            num_samples += preds.size(0)\n",
    "        acc = float(num_correct) / num_samples\n",
    "        print('Got %d / %d correct (%.2f)' % (num_correct, num_samples, 100 * acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def train_part34(model, optimizer, epochs=1):\n",
    "    \"\"\"\n",
    "    Train a model on CIFAR-10 using the PyTorch Module API.\n",
    "    \n",
    "    Inputs:\n",
    "    - model: A PyTorch Module giving the model to train.\n",
    "    - optimizer: An Optimizer object we will use to train the model\n",
    "    - epochs: (Optional) A Python integer giving the number of epochs to train for\n",
    "    \n",
    "    Returns: Nothing, but prints model accuracies during training.\n",
    "    \"\"\"\n",
    "    model = model.to(device=device)  # move the model parameters to CPU/GPU\n",
    "    for e in range(epochs):\n",
    "        for t, (x, y) in enumerate(loader_train):\n",
    "            model.train()  # put model to training mode\n",
    "            x = x.to(device=device, dtype=dtype)  # move to device, e.g. GPU\n",
    "            y = y.to(device=device, dtype=torch.long)\n",
    "            \n",
    "            x.unsqueeze_(1)\n",
    "            scores = model(x)\n",
    "            loss = F.cross_entropy(scores, y)\n",
    "\n",
    "            # Zero out all of the gradients for the variables which the optimizer\n",
    "            # will update.\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # This is the backwards pass: compute the gradient of the loss with\n",
    "            # respect to each  parameter of the model.\n",
    "            loss.backward()\n",
    "\n",
    "            # Actually update the parameters of the model using the gradients\n",
    "            # computed by the backwards pass.\n",
    "            optimizer.step()\n",
    "            \n",
    "#             if e==0 and t==0:\n",
    "#                 print('Initial loss = %.4f' % (loss.item()))\n",
    "#                 check_accuracy_part34(loader_val, model)\n",
    "#                 print()\n",
    "\n",
    "        print('Epoch %d, loss = %.4f' % (e, loss.item()))\n",
    "        check_accuracy_part34(loader_train, model)\n",
    "        check_accuracy_part34(loader_val, model)\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), weight_decay=1e-2, amsgrad=True)\n",
    "# optimizer = optim.SGD(filter(lambda p: p.requires_grad, model.parameters()), lr = 0.01, momentum=0.9)\n",
    "train_part34(model, optimizer, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import KFold\n",
    "# from sklearn import metrics\n",
    "\n",
    "# # for epoch in range(5):\n",
    "# kf = KFold(n_splits=3, shuffle = True)\n",
    "# accuracies=[]\n",
    "# for train_index, test_index in kf.split(x):\n",
    "#     accuracies=[]\n",
    "# #     (N, C1, C2, S) = x.shape \n",
    "# #     x = x.reshape((N, 62, 512, 512))\n",
    "# #     y = y.reshape((y.shape[0]))\n",
    "# #     print(x.shape)\n",
    "# #     print(y.shape)\n",
    "# #     print(train_index)\n",
    "# #     print(test_index)\n",
    "#     xk_train, xk_test = x[train_index], x[test_index]\n",
    "#     yk_train, yk_test = y[train_index], y[test_index]\n",
    "#     net.fit(xk_train,yk_train)\n",
    "#     y_pred = net.predict(xk_test)\n",
    "#     acc = metrics.accuracy_score(yk_test, y_pred)\n",
    "#     accuracies.append(acc)\n",
    "#     print('FinalAccuracy %.4f' % (np.mean(accuracies)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "(N, C1, C2, S) = x_Test.shape\n",
    "x_Test = x_Test.reshape((N, S, C1, C2))\n",
    "y_pred_test = net.predict(x_Test)\n",
    "acc = metrics.accuracy_score(y_Test, y_pred_test)\n",
    "print('TestAccuracy %.4f' % (acc))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
