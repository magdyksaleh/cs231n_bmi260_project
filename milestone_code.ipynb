{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import sampler\n",
    "import skorch\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as T\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using device: cpu\n"
     ]
    }
   ],
   "source": [
    "USE_GPU = True\n",
    "\n",
    "dtype = torch.float32 # we will be using float throughout this tutorial\n",
    "\n",
    "if USE_GPU and torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "# Constant to control how frequently we print train loss\n",
    "print_every = 100\n",
    "\n",
    "print('using device:', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#load the data\n",
    "x = np.load(\"X.npy\")\n",
    "y = np.load(\"y.npy\")\n",
    "\n",
    "x_full = torch.from_numpy(x)\n",
    "y_full = torch.from_numpy(y)\n",
    "x_full = x_full.to(device=device, dtype=dtype)\n",
    "y_full = y_full.to(device=device, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([17, 512, 512, 62])\n",
      "torch.Size([17, 1])\n",
      "torch.Size([29, 512, 512, 62])\n",
      "torch.Size([29, 1])\n"
     ]
    }
   ],
   "source": [
    "#split the data\n",
    "x = x_full[30:,:,:,:]\n",
    "y = y_full[30:]\n",
    "\n",
    "print(x.shape)\n",
    "print(y.shape)\n",
    "\n",
    "x_Test = x_full[0:29,:,:,:]\n",
    "y_Test = y_full[0:29]\n",
    "\n",
    "print(x_Test.shape)\n",
    "print(y_Test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def flatten(x):\n",
    "    N = x.shape[0] # read in N, C, H, W\n",
    "    return x.view(N, -1)  # \"flatten\" the C * H * W values into a single vector per image\n",
    "\n",
    "class Flatten(nn.Module):\n",
    "    def forward(self, x):\n",
    "        return flatten(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "channel_1 = 32\n",
    "channel_2 = 64\n",
    "channel_3 = 32\n",
    "\n",
    "\n",
    "learning_rate = 2.5e-3\n",
    "model = None\n",
    "optimizer = None\n",
    "\n",
    "in_channel = 62\n",
    "num_classes = 3\n",
    "\n",
    "model = nn.Sequential(\n",
    "    nn.Conv2d(in_channel, channel_1, 5, padding=2),\n",
    "    nn.BatchNorm2d(channel_1),\n",
    "    nn.ReLU(),\n",
    "    nn.Conv2d(channel_1, channel_2, 3, padding=1),\n",
    "    nn.BatchNorm2d(channel_2),\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool2d(2),\n",
    "    Flatten(),\n",
    "    nn.Linear((32*512*512)/2, 100),\n",
    "    nn.Linear(100, num_classes)\n",
    ")\n",
    "model = model.to(device=device)\n",
    "\n",
    "from skorch import NeuralNetClassifier\n",
    "\n",
    "net = NeuralNetClassifier(\n",
    "    module=model,\n",
    "    criterion = nn.CrossEntropyLoss,\n",
    "    optimizer=optim.Adam,\n",
    "#     optimizer_momentum = 0.9,\n",
    "    train_split=None,\n",
    "    max_epochs=5,\n",
    "    lr= learning_rate,\n",
    "    warm_start = True,\n",
    "    device = device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([17, 62, 512, 512])\n",
      "torch.Size([17])\n",
      "[ 0  1  2  4  5  8 10 11 13 14 15]\n",
      "[ 3  6  7  9 12 16]\n",
      "      7     1968.7339  122.4494\n",
      "      8     1689.8179  126.3974\n",
      "      9     1616.1758  125.6589\n",
      "     10      767.3795  125.9576\n",
      "     11      600.9477  133.7984\n",
      "FinalAccuracy 0.6667\n",
      "torch.Size([17, 62, 512, 512])\n",
      "torch.Size([17])\n",
      "[ 0  3  4  6  7  9 12 13 14 15 16]\n",
      "[ 1  2  5  8 10 11]\n",
      "     12      379.1372  129.4863\n",
      "     13      496.5664  138.6512\n",
      "     14      390.1367  156.9161\n",
      "     15      118.3768  142.3620\n",
      "     16      588.9722  138.8822\n",
      "FinalAccuracy 0.5000\n",
      "torch.Size([17, 62, 512, 512])\n",
      "torch.Size([17])\n",
      "[ 1  2  3  5  6  7  8  9 10 11 12 16]\n",
      "[ 0  4 13 14 15]\n",
      "     17     1112.1178  144.9799\n",
      "     18      423.8275  145.4350\n",
      "     19      541.4341  144.9793\n",
      "     20      494.2856  150.5864\n",
      "     21      443.8631  158.3380\n",
      "FinalAccuracy 0.2000\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn import metrics\n",
    "\n",
    "# for epoch in range(5):\n",
    "kf = KFold(n_splits=3, shuffle = True)\n",
    "accuracies=[]\n",
    "for train_index, test_index in kf.split(x):\n",
    "    accuracies=[]\n",
    "    (N, C1, C2, S) = x.shape # 17, 62, 512, 512\n",
    "    x = x.reshape((17, 62, 512, 512))\n",
    "    y = y.reshape((y.shape[0]))\n",
    "    print(x.shape)\n",
    "    print(y.shape)\n",
    "    print(train_index)\n",
    "    print(test_index)\n",
    "    xk_train, xk_test = x[train_index], x[test_index]\n",
    "    yk_train, yk_test = y[train_index], y[test_index]\n",
    "    net.fit(xk_train,yk_train)\n",
    "    y_pred = net.predict(xk_test)\n",
    "    acc = metrics.accuracy_score(yk_test, y_pred)\n",
    "    accuracies.append(acc)\n",
    "    print('FinalAccuracy %.4f' % (np.mean(accuracies)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TestAccuracy 0.2414\n"
     ]
    }
   ],
   "source": [
    "(N, C1, C2, S) = x_Test.shape\n",
    "x_Test = x_Test.reshape((N, S, C1, C2))\n",
    "y_pred_test = net.predict(x_Test)\n",
    "acc = metrics.accuracy_score(y_Test, y_pred_test)\n",
    "print('TestAccuracy %.4f' % (acc))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
