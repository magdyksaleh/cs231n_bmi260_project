{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import sampler\n",
    "import skorch\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as T\n",
    "import torchvision.models as models\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using device: cpu\n"
     ]
    }
   ],
   "source": [
    "USE_GPU = True\n",
    "\n",
    "dtype = torch.float32 # we will be using float throughout this tutorial\n",
    "\n",
    "if USE_GPU and torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "# Constant to control how frequently we print train loss\n",
    "print_every = 100\n",
    "\n",
    "print('using device:', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#load the data\n",
    "x = np.load(\"./large_data/X.npy\")\n",
    "y = np.load(\"./large_data/y.npy\")\n",
    "\n",
    "x_full = torch.from_numpy(x)\n",
    "y_full = torch.from_numpy(y)\n",
    "x_full = x_full.to(device=device, dtype=dtype)\n",
    "y_full = y_full.to(device=device, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([40, 512, 512, 62])\n",
      "torch.Size([40, 1])\n",
      "torch.Size([29, 512, 512, 62])\n",
      "torch.Size([29, 1])\n"
     ]
    }
   ],
   "source": [
    "#split the data\n",
    "x = x_full[30:70,:,:,:]\n",
    "y = y_full[30:70]\n",
    "\n",
    "print(x.shape)\n",
    "print(y.shape)\n",
    "\n",
    "x_Test = x_full[0:29,:,:,:]\n",
    "y_Test = y_full[0:29]\n",
    "\n",
    "print(x_Test.shape)\n",
    "print(y_Test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def flatten(x):\n",
    "    N = x.shape[0] # read in N, C, H, W\n",
    "    return x.view(N, -1)  # \"flatten\" the C * H * W values into a single vector per image\n",
    "\n",
    "class Flatten(nn.Module):\n",
    "    def forward(self, x):\n",
    "        return flatten(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "channel_1 = 64\n",
    "channel_2 = 64\n",
    "channel_3 = 128\n",
    "\n",
    "learning_rate = 2.5e-3\n",
    "\n",
    "in_channel = 62\n",
    "num_classes = 3\n",
    "\n",
    "# model = nn.Sequential(\n",
    "#     nn.Conv2d(in_channel, channel_1, 5, padding=2),\n",
    "#     nn.BatchNorm2d(channel_1),\n",
    "#     nn.ReLU(),\n",
    "#     nn.Conv2d(channel_1, channel_2, 3, padding=1),\n",
    "#     nn.BatchNorm2d(channel_2),\n",
    "#     nn.ReLU(),\n",
    "#     nn.MaxPool2d(2),\n",
    "#     Flatten(),\n",
    "#     nn.Linear((32*512*512)/2, num_classes)\n",
    "# )\n",
    "# model = model.to(device=device)\n",
    "\n",
    "resnet18 = models.resnet18(pretrained=True)\n",
    "model = resnet18\n",
    "\n",
    "model.conv1 = nn.Conv2d(in_channel, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "num_ftrs = model.fc.in_features\n",
    "model.fc = nn.Linear(num_ftrs*100, num_classes)\n",
    "\n",
    "from skorch import NeuralNetClassifier\n",
    "\n",
    "net = NeuralNetClassifier(\n",
    "    module=model,\n",
    "    criterion = nn.CrossEntropyLoss,\n",
    "    optimizer=optim.Adam,\n",
    "    train_split=None,\n",
    "    max_epochs=5,\n",
    "    lr = learning_rate,\n",
    "    warm_start = True,\n",
    "    device = device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([40, 62, 512, 512])\n",
      "torch.Size([40])\n",
      "[ 2  4  8  9 10 11 12 14 15 16 18 19 21 22 23 25 26 27 28 30 31 33 36 37 38\n",
      " 39]\n",
      "[ 0  1  3  5  6  7 13 17 20 24 29 32 34 35]\n",
      "  epoch    train_loss       dur\n",
      "-------  ------------  --------\n",
      "      1        \u001b[36m0.9912\u001b[0m  122.7344\n",
      "      2       83.2823  115.4586\n",
      "      3       17.9000  108.4039\n",
      "      4        6.7772  111.2738\n",
      "      5        4.4439  109.1874\n",
      "FinalAccuracy 0.2143\n",
      "torch.Size([40, 62, 512, 512])\n",
      "torch.Size([40])\n",
      "[ 0  1  3  5  6  7  8  9 10 13 15 17 18 19 20 22 24 26 29 30 31 32 33 34 35\n",
      " 36 39]\n",
      "[ 2  4 11 12 14 16 21 23 25 27 28 37 38]\n",
      "      6        4.6350  110.7961\n",
      "      7        3.4626  107.3966\n",
      "      8        1.5131  105.9109\n",
      "      9        2.1221  106.3230\n",
      "     10        2.1959  112.1558\n",
      "FinalAccuracy 0.4615\n",
      "torch.Size([40, 62, 512, 512])\n",
      "torch.Size([40])\n",
      "[ 0  1  2  3  4  5  6  7 11 12 13 14 16 17 20 21 23 24 25 27 28 29 32 34 35\n",
      " 37 38]\n",
      "[ 8  9 10 15 18 19 22 26 30 31 33 36 39]\n",
      "     11      114.9111  107.9736\n",
      "     12       41.2930  106.2204\n",
      "     13       38.4902  103.3168\n",
      "     14       20.2039  104.0246\n",
      "     15       13.1218  105.6090\n",
      "FinalAccuracy 0.0769\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn import metrics\n",
    "\n",
    "# for epoch in range(5):\n",
    "kf = KFold(n_splits=3, shuffle = True)\n",
    "accuracies=[]\n",
    "for train_index, test_index in kf.split(x):\n",
    "    accuracies=[]\n",
    "    (N, C1, C2, S) = x.shape # 17, 62, 512, 512\n",
    "    x = x.reshape((N, 62, 512, 512))\n",
    "    y = y.reshape((y.shape[0]))\n",
    "    print(x.shape)\n",
    "    print(y.shape)\n",
    "    print(train_index)\n",
    "    print(test_index)\n",
    "    xk_train, xk_test = x[train_index], x[test_index]\n",
    "    yk_train, yk_test = y[train_index], y[test_index]\n",
    "    net.fit(xk_train,yk_train)\n",
    "    y_pred = net.predict(xk_test)\n",
    "    acc = metrics.accuracy_score(yk_test, y_pred)\n",
    "    accuracies.append(acc)\n",
    "    print('FinalAccuracy %.4f' % (np.mean(accuracies)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "(N, C1, C2, S) = x_Test.shape\n",
    "x_Test = x_Test.reshape((N, S, C1, C2))\n",
    "y_pred_test = net.predict(x_Test)\n",
    "acc = metrics.accuracy_score(y_Test, y_pred_test)\n",
    "print('TestAccuracy %.4f' % (acc))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
