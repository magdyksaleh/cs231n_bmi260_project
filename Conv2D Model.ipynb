{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import sampler\n",
    "from tqdm import tnrange, tqdm_notebook, tqdm\n",
    "\n",
    "import skorch\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as T\n",
    "import torchvision.models as models\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "# matplotlib.use('agg')\n",
    "import matplotlib.pyplot as plt\n",
    "from Lung_dataset import ILDDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "USE_GPU = True\n",
    "\n",
    "dtype = torch.float32 # we will be using float throughout this tutorial\n",
    "\n",
    "if USE_GPU and torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "# Constant to control how frequently we print train loss\n",
    "print_every = 100\n",
    "\n",
    "print('using device:', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_TOTAL = 1968\n",
    "NUM_TRAIN = 1783\n",
    "\n",
    "#add path as absolute path for root dir\n",
    "\n",
    "im_size = 128\n",
    "\n",
    "lung_dataset_train = ILDDataset(csv_file=r'C:/Users/Akrofi/Desktop/CS 231/Project/train_labels.csv', \n",
    "                          root_dir=r'C:/Users/Akrofi/Desktop/CS 231/Project/train',mask=True, train=True, resize=im_size)#, transform=transform)\n",
    "\n",
    "lung_dataset_validation = ILDDataset(csv_file=r'C:/Users/Akrofi/Desktop/CS 231/Project/train_labels.csv', \n",
    "                           root_dir=r'C:/Users/Akrofi/Desktop/CS 231/Project/validation',mask=True, train=False, resize=im_size)#, transform=transform)\n",
    "\n",
    "#add path as absolute path for root dir\n",
    "lung_dataset_test = ILDDataset(csv_file=r'C:/Users/Akrofi/Desktop/CS 231/Project/test_labels.csv', \n",
    "                          root_dir=r'C:/Users/Akrofi/Desktop/CS 231/Project/test', mask=True, train=False, resize=im_size)#, transform=transform)\n",
    "\n",
    "\n",
    "weight0= 1/35\n",
    "weight1= 1/18\n",
    "weight2= 1/47\n",
    "\n",
    "weights = []\n",
    "for i in tnrange(1783):\n",
    "    sample = lung_dataset_train[i]\n",
    "    if sample[1] == 0:\n",
    "        weights.append(weight0)\n",
    "        \n",
    "    elif sample[1] == 1:\n",
    "        weights.append(weight1)\n",
    "    else:\n",
    "        weights.append(weight2)\n",
    "\n",
    "sampler = sampler.WeightedRandomSampler(torch.cuda.DoubleTensor(weights), len(weights) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loader_train = DataLoader(lung_dataset_train, batch_size= 16,\n",
    "                          sampler = sampler)\n",
    "\n",
    "loader_val = DataLoader(lung_dataset_validation, batch_size=16,\n",
    "                        sampler = torch.utils.data.sampler.SubsetRandomSampler(range(190)))\n",
    "\n",
    "loader_test = DataLoader(lung_dataset_test, batch_size=16, sampler = torch.utils.data.sampler.SubsetRandomSampler(range(370)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#show datasample\n",
    "sample = lung_dataset_test[374]\n",
    "plt.imshow(sample[0], cmap='gray')\n",
    "plt.show()\n",
    "print(\"label: \" + str(sample[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def flatten(x):\n",
    "    N = x.shape[0] # read in N, C, H, W\n",
    "    return x.view(N, -1)  # \"flatten\" the C * H * W values into a single vector per image\n",
    "\n",
    "class Flatten(nn.Module):\n",
    "    def forward(self, x):\n",
    "        return flatten(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_model(freeze=False):\n",
    "    \"\"\"\n",
    "    Used to fetch model for classification\n",
    "    \"\"\"\n",
    "\n",
    "    num_classes = 3\n",
    "\n",
    "    model = models.resnet50(pretrained=True)\n",
    "    model.avgpool = nn.AvgPool2d(1, stride=1)\n",
    "    model.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=1, bias=False)\n",
    "    if(freeze==True):\n",
    "        for param in model.parameters():\n",
    "            param.requires_grad = False\n",
    "    model.fc = nn.Linear(32768, num_classes)\n",
    "    \n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##### From CS 231N\n",
    "def check_accuracy(loader, model, train=False, val = False):\n",
    "    predictedStore = []\n",
    "    solutionStore = []\n",
    "    if loader.dataset.train and train == True:\n",
    "        print('Checking accuracy on training set')\n",
    "    elif val:\n",
    "        print('Checking accuracy on validation set')\n",
    "    else:\n",
    "        print('Checking accuracy on test set')   \n",
    "    num_correct = 0\n",
    "    num_samples = 0\n",
    "    model.eval()  # set model to evaluation mode\n",
    "    with torch.no_grad():\n",
    "        for x, y in loader:\n",
    "            x = x.to(device=device, dtype=dtype)  # move to device, e.g. GPU\n",
    "            x.unsqueeze_(1)\n",
    "            y = y.to(device=device, dtype=torch.long)\n",
    "            scores = model(x)\n",
    "            _, preds = scores.max(1)\n",
    "            predictedStore.append(preds.view(-1,).cpu().numpy().tolist())\n",
    "            solutionStore.append(y.data.view(-1,).cpu().numpy().tolist())\n",
    "            \n",
    "            num_correct += (preds == y).sum()\n",
    "            num_samples += preds.size(0)\n",
    "        acc = float(num_correct) / num_samples      \n",
    "        print('Got %d / %d correct (%.2f)' % (num_correct, num_samples, 100 * acc))\n",
    "        \n",
    "    return acc,predictedStore,solutionStore\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##### From CS 231N\n",
    "def train(model, optimizer, epochs=1, overfit=False):\n",
    "    \"\"\"\n",
    "    Inputs:\n",
    "    - model: A PyTorch Module giving the model to train.\n",
    "    - optimizer: An Optimizer object we will use to train the model\n",
    "    - epochs: (Optional) A Python integer giving the number of epochs to train for\n",
    "    \n",
    "    Returns: Nothing, but prints model accuracies during training.\n",
    "    \"\"\"\n",
    "    model = model.to(device=device)  # move the model parameters to CPU/GPU\n",
    "    best_acc = 0;\n",
    "    for e in range(epochs):\n",
    "        for t, (x, y) in enumerate(loader_train):\n",
    "            model.train()  # put model to training mode\n",
    "            x = x.to(device=device, dtype=dtype)  # move to device, e.g. GPU\n",
    "            y = y.to(device=device, dtype=torch.long)\n",
    "            \n",
    "            # Implemet Weighted Loss\n",
    "            weights = torch.tensor([1/35,1/18, 1/47], device= device, dtype=dtype)\n",
    "            x.unsqueeze_(1)\n",
    "            scores = model(x)\n",
    "            Loss = nn.CrossEntropyLoss(weight = weights)\n",
    "            loss = Loss(scores, y)\n",
    "\n",
    "\n",
    "            # Zero out all of the gradients for the variables which the optimizer\n",
    "            # will update.\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # This is the backwards pass: compute the gradient of the loss with\n",
    "            # respect to each  parameter of the model.\n",
    "            loss.backward()\n",
    "\n",
    "            # Actually update the parameters of the model using the gradients\n",
    "            # computed by the backwards pass.\n",
    "            optimizer.step()\n",
    "            \n",
    "        print('Iteration %d, loss = %.4f' % (t, loss.item()))\n",
    "        if(overfit):\n",
    "            _,predictedStoreTrain,solutionStoreTrain = check_accuracy(loader_train, model, train=True)\n",
    "        acc,predictedStoreVal,solutionStoreVal = check_accuracy(loader_val, model, val = True)\n",
    "        if acc > best_acc:\n",
    "            #Save Best Model\n",
    "            best_acc = acc\n",
    "            best_model = model\n",
    "            predStoreTrain = predictedStoreTrain\n",
    "            solStoreTrain = solutionStoreTrain\n",
    "            predStoreVal = predictedStoreVal\n",
    "            solStoreVal = solutionStoreVal\n",
    "        print()\n",
    "    return best_model,predStoreTrain,solStoreTrain,predStoreVal,solStoreVal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From CS 231N\n",
    "model1 = get_model(freeze = True)\n",
    "optimizer = optim.Adam(filter(lambda p: p.requires_grad, model1.parameters()), lr=0.0001, weight_decay= 1e-5)\n",
    "best_model,predStoreTrain,solStoreTrain,predStoreVal,solStoreVal = train(model1, optimizer, epochs= 5, overfit=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check Test set\n",
    "acc,predStoreTest,solStoreTest = check_accuracy(loader_test, best_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From SciKit Documentation Page\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn import svm, datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "\n",
    "    \n",
    "    \n",
    "##Actual Plots\n",
    "\n",
    "y_pred_train = np.concatenate([np.array(i) for i in predStoreTrain])\n",
    "y_train = np.concatenate([np.array(i) for i in solStoreTrain])\n",
    "\n",
    "y_pred_val = np.concatenate([np.array(i) for i in predStoreVal]) \n",
    "y_val = np.concatenate([np.array(i) for i in solStoreVal])\n",
    "\n",
    "y_pred_test = np.concatenate([np.array(i) for i in predStoreTest]) \n",
    "y_test = np.concatenate([np.array(i) for i in solStoreTest])\n",
    "\n",
    "cnf_matrix1 = confusion_matrix(y_train, y_pred_train)\n",
    "cnf_matrix2 = confusion_matrix( y_val, y_pred_val)\n",
    "cnf_matrix3 = confusion_matrix(y_test, y_pred_test)\n",
    "\n",
    "\n",
    "\n",
    "class_names = [0,1,2]\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "# Plot non-normalized confusion matrix\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix1, classes=class_names,\n",
    "                      title='Normalized confusion matrix - Train')\n",
    "\n",
    "# Plot normalized confusion matrix\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix2, classes=class_names,\n",
    "                      title='Normalized confusion matrix - Val')\n",
    "\n",
    "# Plot normalized confusion matrix\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix3, classes=class_names,\n",
    "                      title='Normalized confusion matrix - Test')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From SciKit Documentation Page\n",
    "    \n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn import svm, datasets\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "\n",
    "y_test = label_binarize(y_test, classes = [0,1,2])\n",
    "y_pred_test = label_binarize(y_pred_test, classes = [0,1,2])\n",
    "y_val = label_binarize(y_val, classes = [0,1,2])\n",
    "y_pred_val = label_binarize(y_pred_val, classes = [0,1,2])\n",
    "\n",
    "precision = dict()\n",
    "recall = dict()\n",
    "average_precision = dict()\n",
    "n_classes = 3\n",
    "for i in range(n_classes):\n",
    "    precision[i], recall[i], _ = precision_recall_curve(y_val[:, i],\n",
    "                                                        y_pred_val[:, i])\n",
    "    average_precision[i] = average_precision_score(y_val[:, i], y_pred_val[:, i])\n",
    "\n",
    "# Compute micro-average ROC curve and ROC area\n",
    "precision[\"micro\"], recall[\"micro\"], _ = precision_recall_curve(y_val.ravel(),\n",
    "    y_pred_val.ravel())\n",
    "average_precision[\"micro\"] = average_precision_score(y_val, y_pred_val,\n",
    "                                                     average=\"micro\")\n",
    "\n",
    "# Plot Precision-Recall curve\n",
    "plt.clf()\n",
    "plt.plot(recall[0], precision[0], label='Precision-Recall curve')\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.title('Precision-Recall example: AUC={0:0.2f}'.format(average_precision[0]))\n",
    "plt.legend(loc=\"lower left\")\n",
    "plt.show()\n",
    "\n",
    "# Plot Precision-Recall curve for each class\n",
    "plt.clf()\n",
    "plt.plot(recall[\"micro\"], precision[\"micro\"],\n",
    "         label='micro-average Precision-recall curve (area = {0:0.2f})'\n",
    "               ''.format(average_precision[\"micro\"]))\n",
    "for i in range(n_classes):\n",
    "    plt.plot(recall[i], precision[i],\n",
    "             label='Precision-recall curve of class {0} (area = {1:0.2f})'\n",
    "                   ''.format(i, average_precision[i]))\n",
    "\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.title('Extension of Precision-Recall curve to multi-class')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n",
    "\n",
    "print(precision)\n",
    "print(recall)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
