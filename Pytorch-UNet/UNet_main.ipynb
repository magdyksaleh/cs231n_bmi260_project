{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UNet model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running the UNet from here "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import sampler\n",
    "import skorch\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.models as models\n",
    "import collections\n",
    "import torch.backends.cudnn as cudnn\n",
    "from torch.autograd import Variable\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from optparse import OptionParser\n",
    "from eval import eval_net\n",
    "from unet import UNet\n",
    "from utils import *\n",
    "\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from UNet_Loader import ILDDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_TOTAL = 885\n",
    "NUM_TRAIN = 700\n",
    "\n",
    "lung_dataset_train = ILDDataset(cystic_path='/Users/magdy/Desktop/Stanford Spring/BMI260/Project/Data/cystic_dataset_masks/Train',\n",
    "                          root_dir='/Users/magdy/Desktop/Stanford Spring/BMI260/Project/Data/Cystic Dataset/Train',\n",
    "                          mask=True, HU=True, resize=256)\n",
    "\n",
    "lung_dataset_test = ILDDataset(cystic_path='/Users/magdy/Desktop/Stanford Spring/BMI260/Project/Data/cystic_dataset_masks/Test',\n",
    "                          root_dir='/Users/magdy/Desktop/Stanford Spring/BMI260/Project/Data/Cystic Dataset/Test',\n",
    "                          mask=True, HU=True, resize=256)\n",
    "\n",
    "loader_train = DataLoader(lung_dataset_train, batch_size=4, \n",
    "                          sampler=sampler.SubsetRandomSampler(range(NUM_TRAIN)))\n",
    "\n",
    "loader_val = DataLoader(lung_dataset_train, batch_size=4, \n",
    "                          sampler=sampler.SubsetRandomSampler(range(NUM_TRAIN, NUM_TOTAL)))\n",
    "\n",
    "loader_test = DataLoader(lung_dataset_test, batch_size=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using device: cpu\n"
     ]
    }
   ],
   "source": [
    "USE_GPU = True\n",
    "\n",
    "dtype = torch.float32 # we will be using float throughout this tutorial\n",
    "\n",
    "if USE_GPU and torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "# Constant to control how frequently we print train loss\n",
    "print_every = 100\n",
    "\n",
    "print('using device:', device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_accuracy(loader, model, train=False):\n",
    "    if loader.dataset.train and train == True:\n",
    "        print('Checking accuracy on training set')\n",
    "    elif loader.dataset.train:\n",
    "        print('Checking accuracy on validation set')\n",
    "    else:\n",
    "        print('Checking accuracy on test set')   \n",
    "    num_correct = 0\n",
    "    num_samples = 0\n",
    "    model.eval()  # set model to evaluation mode\n",
    "    with torch.no_grad():\n",
    "        for x, y in loader:\n",
    "            x = x.to(device=device, dtype=dtype)  # move to device, e.g. GPU\n",
    "            y = y.to(device=device, dtype=torch.long)\n",
    "            \n",
    "            [N,H,W] =  [*x.size()]\n",
    "            \n",
    "            \n",
    "            a = collections.Counter(y).most_common()[0][0]\n",
    "            y = torch.LongTensor([a])\n",
    "            y = y.to(device=device, dtype=torch.long)\n",
    "\n",
    "                                \n",
    "            scores = model(x.view(1, 1, N, H , W))\n",
    "            _, preds = scores.max(1)\n",
    "            num_correct += (preds == y).sum()\n",
    "            num_samples += preds.size(0)\n",
    "        acc = float(num_correct) / num_samples      \n",
    "        print('Got %d / %d correct (%.2f)' % (num_correct, num_samples, 100 * acc))\n",
    "        \n",
    "    return acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train function\n",
    "\n",
    "def train_net(net, epochs=5, batch_size=2, lr=0.1, val_percent=0.05, cp=True, gpu=False):\n",
    "    optimizer = optim.SGD(net.parameters(),\n",
    "                          lr=lr, momentum=0.9, weight_decay=0.0005)\n",
    "    criterion = nn.BCELoss()\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        print('Starting epoch {}/{}.'.format(epoch + 1, epochs))\n",
    "\n",
    "        # reset the generators\n",
    "#         train = get_imgs_and_masks(iddataset['train'], dir_img, dir_mask)\n",
    "#         val = get_imgs_and_masks(iddataset['val'], dir_img, dir_mask)\n",
    "\n",
    "        epoch_loss = 0\n",
    "\n",
    "        if 1:\n",
    "            val_dice = eval_net(net, loader_val, device, gpu)\n",
    "            print('Validation Dice Coeff: {}'.format(val_dice))\n",
    "            \n",
    "        for t, (X, y) in enumerate(loader_train):\n",
    "            X = X.to(device=device, dtype=dtype)  # move to device, e.g. GPU\n",
    "            y = y.to(device=device, dtype=dtype)\n",
    "            X.unsqueeze_(1)\n",
    "            y.unsqueeze_(1)\n",
    "\n",
    "            if gpu:\n",
    "                X = Variable(X).cuda()\n",
    "                y = Variable(y).cuda()\n",
    "            else:\n",
    "                X = Variable(X)\n",
    "                y = Variable(y)\n",
    "\n",
    "            y_pred = net(X)\n",
    "            probs = F.sigmoid(y_pred)\n",
    "            probs_flat = probs.view(-1)\n",
    "\n",
    "            y_flat = y.view(-1)\n",
    "\n",
    "            loss = criterion(probs_flat, y_flat.float())\n",
    "            epoch_loss += loss.data[0]\n",
    "\n",
    "            if(t%10 == 0):\n",
    "                print('{0:.4f} --- loss: {1:.6f}'.format(t,\n",
    "                                                     loss.data[0]))\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            loss.backward()\n",
    "\n",
    "            optimizer.step()\n",
    "            if(t>5):\n",
    "                break\n",
    "        print('Epoch finished ! Loss: {}'.format(epoch_loss / i))\n",
    "\n",
    "        if cp:\n",
    "            torch.save(net.state_dict(),\n",
    "                       dir_checkpoint + 'CP{}.pth'.format(epoch + 1))\n",
    "\n",
    "            print('Checkpoint {} saved !'.format(epoch + 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 1/5.\n",
      "Checking accuracy on test set\n"
     ]
    }
   ],
   "source": [
    "# # if __name__ == '__main__':\n",
    "# parser = OptionParser()\n",
    "# parser.add_option('-e', '--epochs', dest='epochs', default=5, type='int',\n",
    "#                   help='number of epochs')\n",
    "# parser.add_option('-b', '--batch-size', dest='batchsize', default=10,\n",
    "#                   type='int', help='batch size')\n",
    "# parser.add_option('-l', '--learning-rate', dest='lr', default=0.1,\n",
    "#                   type='float', help='learning rate')\n",
    "# parser.add_option('-g', '--gpu', action='store_true', dest='gpu',\n",
    "#                   default=False, help='use cuda')\n",
    "# parser.add_option('-c', '--load', dest='load',\n",
    "#                   default=False, help='load file model')\n",
    "\n",
    "# (options, args) = parser.parse_args()\n",
    "\n",
    "net = UNet(1, 1)\n",
    "\n",
    "# if options.load:\n",
    "#     net.load_state_dict(torch.load(options.load))\n",
    "#     print('Model loaded from {}'.format(options.load))\n",
    "\n",
    "# if options.gpu:\n",
    "#     net.cuda()\n",
    "#     cudnn.benchmark = True\n",
    "\n",
    "try:\n",
    "    train_net(net) # , options.epochs, options.batchsize, options.lr,gpu=options.gpu)\n",
    "except KeyboardInterrupt:\n",
    "    torch.save(net.state_dict(), 'INTERRUPTED.pth')\n",
    "    print('Saved interrupt')\n",
    "    try:\n",
    "        sys.exit(0)\n",
    "    except SystemExit:\n",
    "        os._exit(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
